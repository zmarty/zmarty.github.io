---
layout: post
title: "Chinese open weight models overtaking US ones"
date: 2025-11-02 11:05:00 -0700
categories: [AI, Development]
tags: [llm]
description: "TODO"
---

The downfall of Llama and these rise of Chinese models

Countries of the top open weights models by intelligence
<img width="1000" height="432" alt="image" src="https://github.com/user-attachments/assets/d2e3564b-c3f0-4325-8f5b-b00be41a080e" />

Cumulative downloads of leading LLM organizations from key open-weight AI labs:
<img width="1000" height="797" alt="15f8f279-680a-4f73-aee3-842655210c30" src="https://github.com/user-attachments/assets/fc52d0b9-cecc-4b5b-9ee1-3812e1a8ef33" />

Performance Intelligence Ratings between April 2024 and August 2025 across China, USA, and EU.
<img width="1000" height="667" alt="image" src="https://github.com/user-attachments/assets/562b1e3c-60f7-4dc2-91d7-eba0bded04af" />

There are 20+ notable Chinese organizations producing open models
<img width="1000" height="615" alt="image" src="https://github.com/user-attachments/assets/73a5adc7-e213-4336-aa44-44b1bd3a9a7e" />

Closing gap
<img width="1000" height="510" alt="c4c2ac11-6da5-412a-b565-9653eac2411f" src="https://github.com/user-attachments/assets/9c19ba05-7154-4673-824b-d3f0d17f777b" />

Cumulative downloads of leading LLM organizations from different continents for all major models released after ChatGPT.
China overtook the U.S. ~August 2025.
<img width="1000" height="710" alt="4863b0bb-31e2-4bb5-b909-7122c11b964e" src="https://github.com/user-attachments/assets/bcbacd38-336e-4528-afdb-660c39ed845d" />

Per-month proportion of downstream fine-tuned models built on models from leading open-weight LLMs in key regions. Chinese models have >50% share.
<img width="1000" height="708" alt="image" src="https://github.com/user-attachments/assets/23163e25-e12d-4a0c-ad34-debb9855402d" />

Both Cursor and Cognition (Windsurf) new models today are speculated to be built on Chinese base models!
<img width="1000" height="353" alt="image" src="https://github.com/user-attachments/assets/a4e876c0-7656-4a3e-b714-87231d5d709f" />

Silicon Valley is migrating from expensive closed-source models to cheaper open-source alternatives
https://www.reddit.com/r/LocalLLaMA/comments/1ohdl9q/silicon_valley_is_migrating_from_expensive/

"These days, when entrepreneurs pitch at Andreessen Horowitz (a16z), a major Silicon Valley venture-capital firm, there’s a high chance their startups are running on Chinese models. “I’d say there’s an 80% chance they’re using a Chinese open-source model,” notes Martin Casado, a partner at a16z."
https://archive.ph/peT2Y - China is quietly upstaging America with its open models
https://www.reddit.com/r/Futurology/comments/1my7p5i/80_of_ai_startups_applying_for_vc_funding_with/

Chamath Palihapitiya just made a bold statement on the All-In Podcast:
He’s switching parts of his company’s AI stack from OpenAI / Anthropic to Kimi K2, despite being a top-tier Amazon Bedrock customer.
His reason: “It’s way more performant and a ton cheaper.”
https://x.com/CodeByPoonam/status/1982763665314267435

<blockquote class="twitter-tweet" data-media-max-width="560"><p lang="en" dir="ltr">Chamath Palihapitiya just made a bold statement on the All-In Podcast:<br><br>He’s switching parts of his company’s AI stack from OpenAI / Anthropic to Kimi K2, despite being a top-tier Amazon Bedrock customer.<br><br>His reason: “It’s way more performant and a ton cheaper.” <a href="https://t.co/l6qQWMnTIA">pic.twitter.com/l6qQWMnTIA</a></p>&mdash; Poonam Soni (@CodeByPoonam) <a href="https://twitter.com/CodeByPoonam/status/1982763665314267435?ref_src=twsrc%5Etfw">October 27, 2025</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Intelligence vs active parameters
<img width="1000" height="476" alt="image" src="https://github.com/user-attachments/assets/207cd4ba-38b9-4b5b-b1b5-985ef85460b5" />


This post is based HEAVILY on a [talk](https://www.interconnects.ai/p/state-of-open-models-2025) and [slides](https://docs.google.com/presentation/d/1f1Et0Mz8zb1yVCnCgdYSy4tAa0Kv_gKT4wPEg1XPdUA/edit?slide=id.p#slide=id.p) presented by Nathan Lambert on The State of Open Models. Further augmented with more recent developments and notable quotes.

Models used to write and edit this post:
- Text editing: Quantized GLM-4.5-Air [running locally](https://huggingface.co/QuantTrio/GLM-4.5-Air-AWQ-FP16Mix) at full context on an single [NVIDIA RTX Pro 6000](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/rtx-pro-6000/).
- Image editing: [Google Nano Banana](https://aistudio.google.com/models/gemini-2-5-flash-image).